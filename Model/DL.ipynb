{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "Using cached joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
      "Using cached threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.0 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 09:54:17.382548: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 09:54:17.386158: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 09:54:17.422563: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 09:54:18.425591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KDDTest+.txt': 22544,\n",
       " 'KDDTest-21.txt': 11850,\n",
       " 'KDDTrain+.txt': 125973,\n",
       " 'KDDTrain+_20Percent.txt': 25192}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "directory = \"nsl-kdd/\"\n",
    "document_counts = {}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\")  :\n",
    "        document_counts[filename] = len(open(os.path.join(directory, filename), 'r').readlines())\n",
    "document_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train_name = 'KDDTrain+.txt'\n",
    "file_test_name = 'KDDTest+.txt'\n",
    "column_names = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', \n",
    "                'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', \n",
    "                'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', \n",
    "                'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', \n",
    "                'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', \n",
    "                'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'sub_label', 'level']\n",
    "column_drops = ['level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (125973, 42)\n",
      "Shape test: (22544, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>sub_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22539</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>smtp</td>\n",
       "      <td>SF</td>\n",
       "      <td>794</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22540</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>317</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22541</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>54540</td>\n",
       "      <td>8314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22542</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>domain_u</td>\n",
       "      <td>SF</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>252</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22543</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>sunrpc</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>mscan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148517 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0             0           tcp  ftp_data   SF        491          0     0   \n",
       "1             0           udp     other   SF        146          0     0   \n",
       "2             0           tcp   private   S0          0          0     0   \n",
       "3             0           tcp      http   SF        232       8153     0   \n",
       "4             0           tcp      http   SF        199        420     0   \n",
       "...         ...           ...       ...  ...        ...        ...   ...   \n",
       "22539         0           tcp      smtp   SF        794        333     0   \n",
       "22540         0           tcp      http   SF        317        938     0   \n",
       "22541         0           tcp      http   SF      54540       8314     0   \n",
       "22542         0           udp  domain_u   SF         42         42     0   \n",
       "22543         0           tcp    sunrpc  REJ          0          0     0   \n",
       "\n",
       "       wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0                   0       0    0  ...                  25   \n",
       "1                   0       0    0  ...                   1   \n",
       "2                   0       0    0  ...                  26   \n",
       "3                   0       0    0  ...                 255   \n",
       "4                   0       0    0  ...                 255   \n",
       "...               ...     ...  ...  ...                 ...   \n",
       "22539               0       0    0  ...                 141   \n",
       "22540               0       0    0  ...                 255   \n",
       "22541               0       0    2  ...                 255   \n",
       "22542               0       0    0  ...                 252   \n",
       "22543               0       0    0  ...                  21   \n",
       "\n",
       "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                        0.17                    0.03   \n",
       "1                        0.00                    0.60   \n",
       "2                        0.10                    0.05   \n",
       "3                        1.00                    0.00   \n",
       "4                        1.00                    0.00   \n",
       "...                       ...                     ...   \n",
       "22539                    0.72                    0.06   \n",
       "22540                    1.00                    0.00   \n",
       "22541                    1.00                    0.00   \n",
       "22542                    0.99                    0.01   \n",
       "22543                    0.08                    0.03   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                             0.17                         0.00   \n",
       "1                             0.88                         0.00   \n",
       "2                             0.00                         0.00   \n",
       "3                             0.03                         0.04   \n",
       "4                             0.00                         0.00   \n",
       "...                            ...                          ...   \n",
       "22539                         0.01                         0.01   \n",
       "22540                         0.01                         0.01   \n",
       "22541                         0.00                         0.00   \n",
       "22542                         0.00                         0.00   \n",
       "22543                         0.00                         0.00   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                      0.00                      0.00                  0.05   \n",
       "1                      0.00                      0.00                  0.00   \n",
       "2                      1.00                      1.00                  0.00   \n",
       "3                      0.03                      0.01                  0.00   \n",
       "4                      0.00                      0.00                  0.00   \n",
       "...                     ...                       ...                   ...   \n",
       "22539                  0.01                      0.00                  0.00   \n",
       "22540                  0.01                      0.00                  0.00   \n",
       "22541                  0.00                      0.00                  0.07   \n",
       "22542                  0.00                      0.00                  0.00   \n",
       "22543                  0.00                      0.00                  0.44   \n",
       "\n",
       "       dst_host_srv_rerror_rate  sub_label  \n",
       "0                          0.00     normal  \n",
       "1                          0.00     normal  \n",
       "2                          0.00    neptune  \n",
       "3                          0.01     normal  \n",
       "4                          0.00     normal  \n",
       "...                         ...        ...  \n",
       "22539                      0.00     normal  \n",
       "22540                      0.00     normal  \n",
       "22541                      0.07       back  \n",
       "22542                      0.00     normal  \n",
       "22543                      1.00      mscan  \n",
       "\n",
       "[148517 rows x 42 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(directory, file_train_name), header=None, names=column_names\n",
    "                      , usecols=lambda x: x not in column_drops)\n",
    "test_df = pd.read_csv(os.path.join(directory, file_test_name),header=None, names=column_names\n",
    "                      , usecols=lambda x: x not in column_drops)\n",
    "df_full = pd.concat([train_df, test_df], ignore_index=True)\n",
    "df_full = pd.concat([train_df, test_df])\n",
    "print(f\"Shape train: {train_df.shape}\")\n",
    "print(f\"Shape test: {test_df.shape}\")\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': 'normal',\n",
       " 'neptune': 'DoS',\n",
       " 'satan': 'DoS',\n",
       " 'smurf': 'DoS',\n",
       " 'apache2': 'DoS',\n",
       " 'back': 'DoS',\n",
       " 'mailbomb': 'DoS',\n",
       " 'teardrop': 'DoS',\n",
       " 'pod': 'DoS',\n",
       " 'land': 'DoS',\n",
       " 'worm': 'DoS',\n",
       " 'udpstorm': 'DoS',\n",
       " 'mscan': 'Probe',\n",
       " 'ipsweep': 'Probe',\n",
       " 'portsweep': 'Probe',\n",
       " 'nmap': 'Probe',\n",
       " 'snmpguess': 'Probe',\n",
       " 'saint': 'Probe',\n",
       " 'guess_passwd': 'U2R',\n",
       " 'processtable': 'U2R',\n",
       " 'buffer_overflow': 'U2R',\n",
       " 'multihop': 'U2R',\n",
       " 'rootkit': 'U2R',\n",
       " 'named': 'U2R',\n",
       " 'ps': 'U2R',\n",
       " 'sendmail': 'U2R',\n",
       " 'xterm': 'U2R',\n",
       " 'xlock': 'U2R',\n",
       " 'phf': 'U2R',\n",
       " 'loadmodule': 'U2R',\n",
       " 'perl': 'U2R',\n",
       " 'sqlattack': 'U2R',\n",
       " 'spy': 'U2R',\n",
       " 'warezmaster': 'R2L',\n",
       " 'snmpgetattack': 'R2L',\n",
       " 'httptunnel': 'R2L',\n",
       " 'warezclient': 'R2L',\n",
       " 'imap': 'R2L',\n",
       " 'ftp_write': 'R2L',\n",
       " 'xsnoop': 'R2L'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_categories = {\n",
    "    'normal': ['normal'],\n",
    "    'DoS': ['neptune', 'satan', 'smurf', 'apache2', 'back', 'mailbomb', 'teardrop', 'pod', 'land', 'worm', 'udpstorm'],\n",
    "    'Probe': ['mscan', 'ipsweep', 'portsweep', 'nmap', 'snmpguess', 'saint'],\n",
    "    'U2R': ['guess_passwd', 'processtable', 'buffer_overflow', 'multihop', 'rootkit', 'named', 'ps', 'sendmail', 'xterm', 'xlock', 'phf', 'loadmodule', 'perl', 'sqlattack', 'spy'],\n",
    "    'R2L': ['warezmaster', 'snmpgetattack', 'httptunnel', 'warezclient', 'imap', 'ftp_write', 'xsnoop']\n",
    "}\n",
    "dict_attack_outcome = {}\n",
    "for clas, subclass in attack_categories.items():\n",
    "    for subclas in subclass:\n",
    "        dict_attack_outcome[subclas] = clas\n",
    "dict_attack_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['label'] = df_full.sub_label.apply(lambda x: dict_attack_outcome[x])\n",
    "train_df['label'] = train_df.sub_label.apply(lambda x: dict_attack_outcome[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_full.drop(['label', 'sub_label'], axis=1), df_full[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_object_X = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output =False).set_output(transform=\"pandas\")\n",
    "X_oh = ohe.fit_transform(X[columns_object_X])\n",
    "X.drop(columns_object_X, axis=1, inplace=True)\n",
    "X = pd.concat([X, X_oh], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_with_sklearn(df, cols):\n",
    "    result = df.copy() \n",
    "    scaler = MinMaxScaler()\n",
    "    result[cols] = scaler.fit_transform(df[cols])\n",
    "    return result\n",
    "def normalize_with_log(df, cols):\n",
    "    result = df.copy() \n",
    "    for col in cols:\n",
    "        result[col] = np.log1p(result[col])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_values_other_than_zero_or_one = X.columns[~((X == 0) | (X == 1)).all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize_with_log(X, columns_with_values_other_than_zero_or_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['DoS', 'Probe', 'R2L', 'U2R', 'normal'], dtype=object)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lohe = OneHotEncoder(sparse_output =False).set_output(transform=\"pandas\")\n",
    "lohe.fit_transform(y)\n",
    "lohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DoS': 0.5204731032065884,\n",
       " 'Probe': 2.9585059760956174,\n",
       " 'R2L': 13.550821167883212,\n",
       " 'U2R': 13.745210550670986,\n",
       " 'normal': 0.3854880992550679}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "y_train_series = df_full['label'].squeeze()\n",
    "class_labels = np.unique(y_train_series)\n",
    "class_weights = compute_class_weight(class_weight='balanced', \n",
    "                                     classes=class_labels, y=y_train_series)\n",
    "class_weight_dict = dict(zip(class_labels, class_weights))\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dict_number = {0: 0.5204731032065884,\n",
    " 1: 2.9585059760956174,\n",
    " 2: 13.550821167883212,\n",
    " 3: 13.745210550670986,\n",
    " 4: 0.3854880992550679}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\n",
    "kfold.get_n_splits(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133665, 122) (14852, 122)\n",
      "(133665, 122) (14852, 122)\n",
      "(133665, 122) (14852, 122)\n",
      "(133665, 122) (14852, 122)\n",
      "(133665, 122) (14852, 122)\n",
      "(133665, 122) (14852, 122)\n",
      "(133665, 122) (14852, 122)\n",
      "(133666, 122) (14851, 122)\n",
      "(133666, 122) (14851, 122)\n",
      "(133666, 122) (14851, 122)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kfold.split(X,y):\n",
    "    train_X_new, test_X_new = X.iloc[train_index], X.iloc[test_index]\n",
    "    train_y_new, test_y_new = y.iloc[train_index], y.iloc[test_index]\n",
    "    print(train_X_new.shape, test_X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">128,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,505</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m10,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m128,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m250,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m2,505\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,001</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m392,001\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,001</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m392,001\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Input(shape=(X.shape[1],1)),\n",
    "\n",
    "    layers.Conv1D(32, kernel_size=(5), strides=1, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=(5),padding='same'),\n",
    "\n",
    "    layers.Conv1D(64, kernel_size=(5), strides=1, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=(5),padding='same'),\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(500),\n",
    "\n",
    "    layers.Dense(500),\n",
    "    \n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_cnn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.8733 - loss: 0.3694 - val_accuracy: 0.9179 - val_loss: 0.2522\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.1724 - val_accuracy: 0.9259 - val_loss: 0.3093\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.1469 - val_accuracy: 0.9280 - val_loss: 0.2300\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9517 - loss: 0.1280 - val_accuracy: 0.9446 - val_loss: 0.1916\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.1165 - val_accuracy: 0.9667 - val_loss: 0.0865\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9587 - loss: 0.1112 - val_accuracy: 0.9258 - val_loss: 0.2192\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9598 - loss: 0.1155 - val_accuracy: 0.9803 - val_loss: 0.0627\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.1086 - val_accuracy: 0.9620 - val_loss: 0.0914\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1076 - val_accuracy: 0.9586 - val_loss: 0.1213\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.1088 - val_accuracy: 0.9643 - val_loss: 0.0895\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.9643145704282251\n",
      "F1 Score: 0.9685538525301319\n",
      "Recall: 0.9643145704282251\n",
      "Fold 2 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1011 - val_accuracy: 0.9529 - val_loss: 0.1176\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.1013 - val_accuracy: 0.9576 - val_loss: 0.1242\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.0983 - val_accuracy: 0.9767 - val_loss: 0.0791\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9605 - loss: 0.0976 - val_accuracy: 0.9437 - val_loss: 0.2830\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9621 - loss: 0.0970 - val_accuracy: 0.9500 - val_loss: 0.1541\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.0873 - val_accuracy: 0.9733 - val_loss: 0.0983\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.0991 - val_accuracy: 0.9707 - val_loss: 0.0882\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.0848 - val_accuracy: 0.9722 - val_loss: 0.0865\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.0912 - val_accuracy: 0.9781 - val_loss: 0.0791\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9632 - loss: 0.0948 - val_accuracy: 0.9729 - val_loss: 0.1063\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.9728656073256127\n",
      "F1 Score: 0.9745456550850994\n",
      "Recall: 0.9728656073256127\n",
      "Fold 3 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9630 - loss: 0.0921 - val_accuracy: 0.9810 - val_loss: 0.0615\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.0783 - val_accuracy: 0.9665 - val_loss: 0.0909\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.0884 - val_accuracy: 0.9241 - val_loss: 0.2009\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.0899 - val_accuracy: 0.9617 - val_loss: 0.1227\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.0856 - val_accuracy: 0.9677 - val_loss: 0.1461\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.0913 - val_accuracy: 0.9651 - val_loss: 0.1005\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.0809 - val_accuracy: 0.9668 - val_loss: 0.0918\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.0901 - val_accuracy: 0.9655 - val_loss: 0.1360\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0834 - val_accuracy: 0.9773 - val_loss: 0.0623\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0980 - val_accuracy: 0.9735 - val_loss: 0.0688\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.973471586318341\n",
      "F1 Score: 0.9747236634717685\n",
      "Recall: 0.973471586318341\n",
      "Fold 4 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9650 - loss: 0.0930 - val_accuracy: 0.9391 - val_loss: 0.2003\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9633 - loss: 0.0924 - val_accuracy: 0.9681 - val_loss: 0.1038\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9624 - loss: 0.1022 - val_accuracy: 0.9762 - val_loss: 0.0680\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.0846 - val_accuracy: 0.9585 - val_loss: 0.1508\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.0957 - val_accuracy: 0.9708 - val_loss: 0.0908\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.0863 - val_accuracy: 0.9542 - val_loss: 0.1370\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.0882 - val_accuracy: 0.9627 - val_loss: 0.0883\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.0851 - val_accuracy: 0.9665 - val_loss: 0.0883\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0880 - val_accuracy: 0.9758 - val_loss: 0.0865\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9645 - loss: 0.0935 - val_accuracy: 0.9531 - val_loss: 0.1549\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.9531376245623485\n",
      "F1 Score: 0.9577310766519062\n",
      "Recall: 0.9531376245623485\n",
      "Fold 5 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.0946 - val_accuracy: 0.9237 - val_loss: 0.2501\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.0869 - val_accuracy: 0.9700 - val_loss: 0.1068\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.0809 - val_accuracy: 0.9645 - val_loss: 0.1149\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9686 - loss: 0.0823 - val_accuracy: 0.9737 - val_loss: 0.0782\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0936 - val_accuracy: 0.9763 - val_loss: 0.0865\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.0773 - val_accuracy: 0.9517 - val_loss: 0.1657\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0854 - val_accuracy: 0.9635 - val_loss: 0.1277\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.0815 - val_accuracy: 0.9611 - val_loss: 0.1250\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.0913 - val_accuracy: 0.9622 - val_loss: 0.0924\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0806 - val_accuracy: 0.9782 - val_loss: 0.0753\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.9781847562617829\n",
      "F1 Score: 0.9791523363085919\n",
      "Recall: 0.9781847562617829\n",
      "Fold 6 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.0800 - val_accuracy: 0.9682 - val_loss: 0.1151\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9661 - loss: 0.0962 - val_accuracy: 0.9671 - val_loss: 0.1108\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.0884 - val_accuracy: 0.9719 - val_loss: 0.0861\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0896 - val_accuracy: 0.9755 - val_loss: 0.0730\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.0937 - val_accuracy: 0.9731 - val_loss: 0.0907\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.0912 - val_accuracy: 0.9473 - val_loss: 0.1750\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0900 - val_accuracy: 0.9744 - val_loss: 0.0872\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.0881 - val_accuracy: 0.9735 - val_loss: 0.0814\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.0804 - val_accuracy: 0.9674 - val_loss: 0.1066\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0869 - val_accuracy: 0.9671 - val_loss: 0.1000\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.9670751413950983\n",
      "F1 Score: 0.9687485076885902\n",
      "Recall: 0.9670751413950983\n",
      "Fold 7 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.0897 - val_accuracy: 0.9529 - val_loss: 0.1723\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.0882 - val_accuracy: 0.9655 - val_loss: 0.1132\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.0964 - val_accuracy: 0.9664 - val_loss: 0.1230\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0870 - val_accuracy: 0.9697 - val_loss: 0.1074\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0824 - val_accuracy: 0.9487 - val_loss: 0.1460\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0879 - val_accuracy: 0.9646 - val_loss: 0.1202\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.0911 - val_accuracy: 0.9767 - val_loss: 0.0722\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.0953 - val_accuracy: 0.9731 - val_loss: 0.1163\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9600 - loss: 0.1126 - val_accuracy: 0.9727 - val_loss: 0.0916\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.0826 - val_accuracy: 0.9664 - val_loss: 0.1012\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.966401831403178\n",
      "F1 Score: 0.9697052520837561\n",
      "Recall: 0.966401831403178\n",
      "Fold 8 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - accuracy: 0.9645 - loss: 0.0960 - val_accuracy: 0.9458 - val_loss: 0.1489\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0854 - val_accuracy: 0.9498 - val_loss: 0.2220\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.0813 - val_accuracy: 0.9760 - val_loss: 0.0755\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 6ms/step - accuracy: 0.9666 - loss: 0.0957 - val_accuracy: 0.9676 - val_loss: 0.1233\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.0880 - val_accuracy: 0.9695 - val_loss: 0.0851\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.0885 - val_accuracy: 0.9720 - val_loss: 0.0990\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0857 - val_accuracy: 0.9139 - val_loss: 0.3949\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.0912 - val_accuracy: 0.9515 - val_loss: 0.1426\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.0823 - val_accuracy: 0.9589 - val_loss: 0.1735\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.0824 - val_accuracy: 0.9665 - val_loss: 0.1011\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.9664669045855498\n",
      "F1 Score: 0.9697918459530838\n",
      "Recall: 0.9664669045855498\n",
      "Fold 9 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.0858 - val_accuracy: 0.9767 - val_loss: 0.0978\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.1114 - val_accuracy: 0.9743 - val_loss: 0.0910\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.0811 - val_accuracy: 0.9698 - val_loss: 0.0986\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.0950 - val_accuracy: 0.9563 - val_loss: 0.1138\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.0946 - val_accuracy: 0.9798 - val_loss: 0.0662\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.0884 - val_accuracy: 0.9818 - val_loss: 0.0677\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.0826 - val_accuracy: 0.9434 - val_loss: 0.1735\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9653 - loss: 0.0922 - val_accuracy: 0.9714 - val_loss: 0.1147\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9685 - loss: 0.0809 - val_accuracy: 0.9725 - val_loss: 0.1034\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.0971 - val_accuracy: 0.9698 - val_loss: 0.0989\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.9697663457006263\n",
      "F1 Score: 0.9728672931833746\n",
      "Recall: 0.9697663457006263\n",
      "Fold 10 --------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.0878 - val_accuracy: 0.9790 - val_loss: 0.0628\n",
      "Epoch 2/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.0877 - val_accuracy: 0.9698 - val_loss: 0.0966\n",
      "Epoch 3/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9661 - loss: 0.0898 - val_accuracy: 0.9554 - val_loss: 0.1597\n",
      "Epoch 4/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1006 - val_accuracy: 0.9728 - val_loss: 0.0802\n",
      "Epoch 5/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.0952 - val_accuracy: 0.9613 - val_loss: 0.1085\n",
      "Epoch 6/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.0949 - val_accuracy: 0.9684 - val_loss: 0.1093\n",
      "Epoch 7/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1054 - val_accuracy: 0.9303 - val_loss: 0.2625\n",
      "Epoch 8/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9619 - loss: 0.0981 - val_accuracy: 0.9794 - val_loss: 0.0677\n",
      "Epoch 9/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0935 - val_accuracy: 0.9729 - val_loss: 0.0790\n",
      "Epoch 10/10\n",
      "\u001b[1m4178/4178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1108 - val_accuracy: 0.9752 - val_loss: 0.0918\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.9751531883374857\n",
      "F1 Score: 0.976084364373139\n",
      "Recall: 0.9751531883374857\n"
     ]
    }
   ],
   "source": [
    "his_acc, his_f1, his_rc = [], [], []\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X,y)):\n",
    "    print(f\"Fold {i+1} --------------------------------\")\n",
    "    train_X_new, test_X_new = X.iloc[train_index], X.iloc[test_index]\n",
    "    train_y_new, test_y_new = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    train_y_new = lohe.transform(train_y_new)\n",
    "    test_y_new = lohe.transform(test_y_new)\n",
    "    \n",
    "    his = model.fit(\n",
    "        train_X_new, train_y_new,\n",
    "        validation_data=(test_X_new, test_y_new), \n",
    "        batch_size=32, \n",
    "        epochs=10,\n",
    "        class_weight=class_weight_dict_number\n",
    "    )\n",
    "    \n",
    "    pred = model.predict(test_X_new)\n",
    "    pred = np.argmax(pred,axis=1)\n",
    "    y_eval = np.argmax(test_y_new,axis=1)\n",
    "    \n",
    "    acc = []\n",
    "    for class_label in sorted(set(y_eval)):\n",
    "        indices = y_eval == class_label\n",
    "        acc.append(accuracy_score(y_eval[indices], pred[indices]))\n",
    "\n",
    "    f1 = f1_score(y_eval, pred, average=None)\n",
    "    recall = recall_score(y_eval, pred, average=None)\n",
    "    his_acc.append(acc)\n",
    "    his_f1.append(f1)\n",
    "    his_rc.append(recall)\n",
    "    \n",
    "    print(\"Accuracy score:\", accuracy_score(y_eval, pred))\n",
    "    print(\"F1 Score:\", f1_score(y_eval, pred, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(y_eval, pred, average='weighted'))\n",
    "    list_model_cnn.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_index = 5\n",
    "best_model = list_model_cnn[best_model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('cnnModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
